library(stringi)    # Será utilizado para limpeza dos dados.
library(readr)      # Será utilizado para limpeza e formatação dos dados.
library(dplyr)      # Será utilizado para formatação de visualização dos dados
library(reshape)    # Será utilizado para formatar os dados para a nuvem de palavras.
setwd("~/GitHub/SUS-Sentiment-Analysis/Projeto")
sent_labels <- c("Raiva", "Antecipação", "Nojo", "Medo", "Alegria",
"Tristeza", "Surpesa", "Confiança", "Negativo", "Positivo", "Neutro")
months <- c("Dez 2019", "Jan 2020", "Fev 2020", "Mar 2020", "Abril 2020",
"Maio 2020")
extra_stpwords <- c("pra", "pro", "né", "tá", "vcs", "tô", "aí")
col_sents <- c(1, 3, 4, 5, 6, 8)
textclean1 <- function(text_list){
aux <- text_list
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
aux <-  readr::parse_character(aux, locale = readr::locale('pt'))
aux <- sapply(aux, function(x) stri_trans_tolower(x,'pt')) # Por tudo em letras minúsculas
aux <- gsub("<[Uu]\\+[a-zA-Z0-9]*>", "",  aux); # Remover Emojis
aux <- gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "",  aux)
aux <- str_replace(aux,"RT @[a-z,A-Z]*: ","")
aux <- gsub("@\\w+", "", aux)
aux <- removeURL(aux)
aux <- gsub(x = aux, pattern = "\n", replacement = " ")
aux <- gsub(x = aux, pattern = '\\"', replacement = ' ')
aux <- gsub("[^%[:alnum:][:blank:]!?]", "", aux)
aux <- gsub(x =  aux, pattern = "saude", "saúde")
aux <- gsub(x =  aux, pattern = "saãde", "saúde")
return(aux)
}
build_corpus <- function(text_listf, rwords=NULL){
tweets_t <- paste(text_listf,collapse=" ")
tweets_S <- VectorSource(tweets_t)
corpus <- Corpus(tweets_S)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("portuguese"))
corpus <- tm_map(corpus, removeWords, rwords)
return(corpus)
}
get_sentiment <- function(text_listf, title="Sentimentos"){
s <- get_nrc_sentiment(text_listf, language = "portuguese")
s$neutral <- (s$positive == s$negative) > 0
s$positive <- (s$positive > s$negative) > 0
s$negative <- (s$positive == 0 & s$neutral == 0) > 0
colnames(s) <- sent_labels
#barplot(colSums(s)[1:8],las=2,col=rainbow(10), ylab= "Quantidade", main=title)
return(s)
}
removeNumPunct <- function(x){
x = gsub("[^[:alnum:]]", " ",x)
return (stripWhitespace(x))
}
#Tokenizando
BigramTokenizer <- function(x){
return(unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE))
}
get_freq <- function(tp, cloud_max_words = 100){
positive_texts <- select(filter(tp, label=="Positivo"), textf)
negative_texts <- select(filter(tp, label=="Negativo"), textf)
#Unindo documentos textuais
data_pos_string <- paste(positive_texts, sep = " ", collapse = " ")
data_neg_string <- paste(negative_texts, sep = " ", collapse = " ")
#Criando Matriz de Termos do Documento
classes = c("Positivo", "Negativo")
corpus_data <- removeNumPunct(c(data_pos_string, data_neg_string))
corpus <- VCorpus(VectorSource(corpus_data))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("portuguese"), extra_stpwords))
tdm <- TermDocumentMatrix(corpus, control = list(tokenize = BigramTokenizer))
tdm_clean <- as.matrix(removeSparseTerms(tdm, 0.8))
colnames(tdm_clean) <- classes
#Gerando nuvem de palavras
comparison.cloud(tdm_clean,max.words=cloud_max_words,random.order=FALSE)
dev.off()
}
get_labels <- function(sentiment){
aux <- sentiment
aux$label <- "Neutro"
aux[aux$Negativo == 1,]$label <- "Negativo"
aux[aux$Positivo == 1,]$label <- "Positivo"
return(aux$label)
}
#tweets <- read.csv("https://raw.githubusercontent.com/henriquefps/SUS-Sentiment-Analysis/master/Projeto/new_tweetsdb.csv", encoding = "UTF-8")
tweets <- read.csv("new_tweetsdb.csv", encoding = "UTF-8")
tweets$date <- str_extract(tweets$date, "[0-9]{4}-[0-9]{2}")
tweets$textf <- textclean1(tweets$tweet)
# Tweets coletados por mês com o termo "Saúde SUS"
tweets %>% group_by(date) %>% count(name = "Tweets")
# Exemplo de dados formatados
as.data.frame(head(tweets %>% select(tweet, textf), n = 1))
ntweets <- 500
ncloud = 500
tp1 <- tweets[tweets$date == "2019-12",][1:ntweets,]
tp2 <- tweets[tweets$date == "2020-01",][1:ntweets,]
tp3 <- tweets[tweets$date == "2020-02",][1:ntweets,]
tp4 <- tweets[tweets$date == "2020-03",][1:ntweets,]
tp5 <- tweets[tweets$date == "2020-04",][1:ntweets,]
tp6 <- tweets[tweets$date == "2020-05",][1:ntweets,]
tp1.s <- get_sentiment(tp1$textf, "Sentimentos Dez 2019")
tp1$label <- get_labels(tp1.s)
tp2.s <- get_sentiment(tp2$textf, "Sentimentos Jan 2020")
tp2$label <- get_labels(tp2.s)
tp3.s <- get_sentiment(tp3$textf, "Sentimentos Fev 2020")
tp3$label <- get_labels(tp3.s)
tp4.s <- get_sentiment(tp4$textf, "Sentimentos Mar 2020")
tp4$label <- get_labels(tp4.s)
tp5.s <- get_sentiment(tp5$textf, "Sentimentos Abril 2020")
tp5$label <- get_labels(tp5.s)
tp6.s <- get_sentiment(tp6$textf, "Sentimentos Maio 2020")
tp6$label <- get_labels(tp6.s)
get_freq(tp1, cloud_max_words = ncloud)
X11()
get_freq(tp1, cloud_max_words = ncloud)
X11()
get_freq(tp1, cloud_max_words = ncloud)
get_freq(tp2, cloud_max_words = ncloud)
get_freq(tp3, cloud_max_words = ncloud)
get_freq(tp4, cloud_max_words = ncloud)
get_freq(tp5, cloud_max_words = ncloud)
get_freq(tp6, cloud_max_words = ncloud)
RStudioGD()
get_freq(tp1, cloud_max_words = ncloud)
RStudioGD()
get_freq(tp1, cloud_max_words = ncloud)
RStudioGD()
get_freq(tp1, cloud_max_words = ncloud)
get_freq(tp2, cloud_max_words = ncloud)
get_freq(tp3, cloud_max_words = ncloud)
get_freq(tp4, cloud_max_words = ncloud)
get_freq(tp5, cloud_max_words = ncloud)
get_freq(tp6, cloud_max_words = ncloud)
options("device")
RStudioGD <- function ()
{
.Call("rs_createGD")
}
RStudioGD()
options("device")
RStudioGD()
get_freq(tp1, cloud_max_words = ncloud)
dev.set(2)
get_freq(tp1, cloud_max_words = ncloud)
dev.set(3)
get_freq(tp1, cloud_max_words = ncloud)
dev.set(RStudioGD())
dev.set(x11())
dev.set(X11())
get_freq(tp1, cloud_max_words = ncloud)
dev.cur() #quartz_off_screen 2
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "digest", "foreach", "Formula", "htmlwidgets", "igraph", "iterators", "knitr", "matrixStats", "network", "NLP", "openssl", "processx", "ps", "quanteda", "quantreg", "readr", "rlang", "rmarkdown", "sandwich", "seqinr", "seriation", "sna", "sp", "statnet.common", "stringdist", "systemfonts", "tibble", "tidytext", "tinytex", "usethis", "withr", "xfun"))
View(x)
library(tm)         # Será utilizado para análise de sentimentos.
library(wordcloud)  # Será utilizado para gerar nuvens de palavras com as palavras mais frequentes no dataset.
library(syuzhet)    # Será utilizado para realizar a classificação do sentimento dos textos.
library(stringr)    # Será utilizado para limpeza dos dados.
library(stringi)    # Será utilizado para limpeza dos dados.
library(readr)      # Será utilizado para limpeza e formatação dos dados.
library(dplyr)      # Será utilizado para formatação de visualização dos dados
library(reshape)    # Será utilizado para formatar os dados para a nuvem de palavras.
setwd("~/GitHub/SUS-Sentiment-Analysis/Projeto")
sent_labels <- c("Raiva", "Antecipação", "Nojo", "Medo", "Alegria",
"Tristeza", "Surpesa", "Confiança", "Negativo", "Positivo", "Neutro")
months <- c("Dez 2019", "Jan 2020", "Fev 2020", "Mar 2020", "Abril 2020",
"Maio 2020")
extra_stpwords <- c("pra", "pro", "né", "tá", "vcs", "tô", "aí")
col_sents <- c(1, 3, 4, 5, 6, 8)
textclean1 <- function(text_list){
aux <- text_list
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
aux <-  readr::parse_character(aux, locale = readr::locale('pt'))
aux <- sapply(aux, function(x) stri_trans_tolower(x,'pt')) # Por tudo em letras minúsculas
aux <- gsub("<[Uu]\\+[a-zA-Z0-9]*>", "",  aux); # Remover Emojis
aux <- gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "",  aux)
aux <- str_replace(aux,"RT @[a-z,A-Z]*: ","")
aux <- gsub("@\\w+", "", aux)
aux <- removeURL(aux)
aux <- gsub(x = aux, pattern = "\n", replacement = " ")
aux <- gsub(x = aux, pattern = '\\"', replacement = ' ')
aux <- gsub("[^%[:alnum:][:blank:]!?]", "", aux)
aux <- gsub(x =  aux, pattern = "saude", "saúde")
aux <- gsub(x =  aux, pattern = "saãde", "saúde")
return(aux)
}
build_corpus <- function(text_listf, rwords=NULL){
tweets_t <- paste(text_listf,collapse=" ")
tweets_S <- VectorSource(tweets_t)
corpus <- Corpus(tweets_S)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("portuguese"))
corpus <- tm_map(corpus, removeWords, rwords)
return(corpus)
}
get_sentiment <- function(text_listf, title="Sentimentos"){
s <- get_nrc_sentiment(text_listf, language = "portuguese")
s$neutral <- (s$positive == s$negative) > 0
s$positive <- (s$positive > s$negative) > 0
s$negative <- (s$positive == 0 & s$neutral == 0) > 0
colnames(s) <- sent_labels
#barplot(colSums(s)[1:8],las=2,col=rainbow(10), ylab= "Quantidade", main=title)
return(s)
}
removeNumPunct <- function(x){
x = gsub("[^[:alnum:]]", " ",x)
return (stripWhitespace(x))
}
#Tokenizando
BigramTokenizer <- function(x){
return(unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE))
}
get_freq <- function(tp, cloud_max_words = 100){
positive_texts <- select(filter(tp, label=="Positivo"), textf)
negative_texts <- select(filter(tp, label=="Negativo"), textf)
#Unindo documentos textuais
data_pos_string <- paste(positive_texts, sep = " ", collapse = " ")
data_neg_string <- paste(negative_texts, sep = " ", collapse = " ")
#Criando Matriz de Termos do Documento
classes = c("Positivo", "Negativo")
corpus_data <- removeNumPunct(c(data_pos_string, data_neg_string))
corpus <- VCorpus(VectorSource(corpus_data))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("portuguese"), extra_stpwords))
tdm <- TermDocumentMatrix(corpus, control = list(tokenize = BigramTokenizer))
tdm_clean <- as.matrix(removeSparseTerms(tdm, 0.8))
colnames(tdm_clean) <- classes
#Gerando nuvem de palavras
comparison.cloud(tdm_clean,max.words=cloud_max_words,random.order=FALSE)
}
get_labels <- function(sentiment){
aux <- sentiment
aux$label <- "Neutro"
aux[aux$Negativo == 1,]$label <- "Negativo"
aux[aux$Positivo == 1,]$label <- "Positivo"
return(aux$label)
}
#tweets <- read.csv("https://raw.githubusercontent.com/henriquefps/SUS-Sentiment-Analysis/master/Projeto/new_tweetsdb.csv", encoding = "UTF-8")
tweets <- read.csv("new_tweetsdb.csv", encoding = "UTF-8")
tweets$date <- str_extract(tweets$date, "[0-9]{4}-[0-9]{2}")
tweets$textf <- textclean1(tweets$tweet)
# Tweets coletados por mês com o termo "Saúde SUS"
tweets %>% group_by(date) %>% count(name = "Tweets")
# Exemplo de dados formatados
as.data.frame(head(tweets %>% select(tweet, textf), n = 1))
library(tm)         # Será utilizado para análise de sentimentos.
library(wordcloud)  # Será utilizado para gerar nuvens de palavras com as palavras mais frequentes no dataset.
library(syuzhet)    # Será utilizado para realizar a classificação do sentimento dos textos.
library(stringr)    # Será utilizado para limpeza dos dados.
library(stringi)    # Será utilizado para limpeza dos dados.
library(readr)      # Será utilizado para limpeza e formatação dos dados.
library(dplyr)      # Será utilizado para formatação de visualização dos dados
library(reshape)    # Será utilizado para formatar os dados para a nuvem de palavras.
setwd("~/GitHub/SUS-Sentiment-Analysis/Projeto")
sent_labels <- c("Raiva", "Antecipação", "Nojo", "Medo", "Alegria",
"Tristeza", "Surpesa", "Confiança", "Negativo", "Positivo", "Neutro")
months <- c("Dez 2019", "Jan 2020", "Fev 2020", "Mar 2020", "Abril 2020",
"Maio 2020")
extra_stpwords <- c("pra", "pro", "né", "tá", "vcs", "tô", "aí")
col_sents <- c(1, 3, 4, 5, 6, 8)
textclean1 <- function(text_list){
aux <- text_list
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
aux <-  readr::parse_character(aux, locale = readr::locale('pt'))
aux <- sapply(aux, function(x) stri_trans_tolower(x,'pt')) # Por tudo em letras minúsculas
aux <- gsub("<[Uu]\\+[a-zA-Z0-9]*>", "",  aux); # Remover Emojis
aux <- gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "",  aux)
aux <- str_replace(aux,"RT @[a-z,A-Z]*: ","")
aux <- gsub("@\\w+", "", aux)
aux <- removeURL(aux)
aux <- gsub(x = aux, pattern = "\n", replacement = " ")
aux <- gsub(x = aux, pattern = '\\"', replacement = ' ')
aux <- gsub("[^%[:alnum:][:blank:]!?]", "", aux)
aux <- gsub(x =  aux, pattern = "saude", "saúde")
aux <- gsub(x =  aux, pattern = "saãde", "saúde")
return(aux)
}
build_corpus <- function(text_listf, rwords=NULL){
tweets_t <- paste(text_listf,collapse=" ")
tweets_S <- VectorSource(tweets_t)
corpus <- Corpus(tweets_S)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("portuguese"))
corpus <- tm_map(corpus, removeWords, rwords)
return(corpus)
}
get_sentiment <- function(text_listf, title="Sentimentos"){
s <- get_nrc_sentiment(text_listf, language = "portuguese")
s$neutral <- (s$positive == s$negative) > 0
s$positive <- (s$positive > s$negative) > 0
s$negative <- (s$positive == 0 & s$neutral == 0) > 0
colnames(s) <- sent_labels
#barplot(colSums(s)[1:8],las=2,col=rainbow(10), ylab= "Quantidade", main=title)
return(s)
}
removeNumPunct <- function(x){
x = gsub("[^[:alnum:]]", " ",x)
return (stripWhitespace(x))
}
#Tokenizando
BigramTokenizer <- function(x){
return(unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE))
}
get_freq <- function(tp, cloud_max_words = 100){
positive_texts <- select(filter(tp, label=="Positivo"), textf)
negative_texts <- select(filter(tp, label=="Negativo"), textf)
#Unindo documentos textuais
data_pos_string <- paste(positive_texts, sep = " ", collapse = " ")
data_neg_string <- paste(negative_texts, sep = " ", collapse = " ")
#Criando Matriz de Termos do Documento
classes = c("Positivo", "Negativo")
corpus_data <- removeNumPunct(c(data_pos_string, data_neg_string))
corpus <- VCorpus(VectorSource(corpus_data))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("portuguese"), extra_stpwords))
tdm <- TermDocumentMatrix(corpus, control = list(tokenize = BigramTokenizer))
tdm_clean <- as.matrix(removeSparseTerms(tdm, 0.8))
colnames(tdm_clean) <- classes
#Gerando nuvem de palavras
comparison.cloud(tdm_clean,max.words=cloud_max_words,random.order=FALSE)
}
get_labels <- function(sentiment){
aux <- sentiment
aux$label <- "Neutro"
aux[aux$Negativo == 1,]$label <- "Negativo"
aux[aux$Positivo == 1,]$label <- "Positivo"
return(aux$label)
}
#tweets <- read.csv("https://raw.githubusercontent.com/henriquefps/SUS-Sentiment-Analysis/master/Projeto/new_tweetsdb.csv", encoding = "UTF-8")
tweets <- read.csv("new_tweetsdb.csv", encoding = "UTF-8")
tweets$date <- str_extract(tweets$date, "[0-9]{4}-[0-9]{2}")
tweets$textf <- textclean1(tweets$tweet)
# Tweets coletados por mês com o termo "Saúde SUS"
tweets %>% group_by(date) %>% count(name = "Tweets")
# Exemplo de dados formatados
as.data.frame(head(tweets %>% select(tweet, textf), n = 1))
ntweets <- 500
ncloud = 500
tp1 <- tweets[tweets$date == "2019-12",][1:ntweets,]
tp2 <- tweets[tweets$date == "2020-01",][1:ntweets,]
tp3 <- tweets[tweets$date == "2020-02",][1:ntweets,]
tp4 <- tweets[tweets$date == "2020-03",][1:ntweets,]
tp5 <- tweets[tweets$date == "2020-04",][1:ntweets,]
tp6 <- tweets[tweets$date == "2020-05",][1:ntweets,]
tp1.s <- get_sentiment(tp1$textf, "Sentimentos Dez 2019")
tp1$label <- get_labels(tp1.s)
tp2.s <- get_sentiment(tp2$textf, "Sentimentos Jan 2020")
tp2$label <- get_labels(tp2.s)
tp3.s <- get_sentiment(tp3$textf, "Sentimentos Fev 2020")
tp3$label <- get_labels(tp3.s)
tp4.s <- get_sentiment(tp4$textf, "Sentimentos Mar 2020")
tp4$label <- get_labels(tp4.s)
tp5.s <- get_sentiment(tp5$textf, "Sentimentos Abril 2020")
tp5$label <- get_labels(tp5.s)
tp6.s <- get_sentiment(tp6$textf, "Sentimentos Maio 2020")
tp6$label <- get_labels(tp6.s)
par()
get_freq(tp1, cloud_max_words = ncloud)
par()
get_freq(tp2, cloud_max_words = ncloud)
par()
get_freq(tp3, cloud_max_words = ncloud)
par()
get_freq(tp4, cloud_max_words = ncloud)
par()
get_freq(tp5, cloud_max_words = ncloud)
par()
get_freq(tp6, cloud_max_words = ncloud)
()
par()
par(mfrow = c(1,1))
get_freq(tp1, cloud_max_words = ncloud)
par(mfrow = c(1,1))
get_freq(tp2, cloud_max_words = ncloud)
par(mfrow = c(1,1))
get_freq(tp3, cloud_max_words = ncloud)
par(mfrow = c(1,1))
get_freq(tp4, cloud_max_words = ncloud)
par(mfrow = c(1,1))
get_freq(tp5, cloud_max_words = ncloud)
par(mfrow = c(1,1))
get_freq(tp6, cloud_max_words = ncloud)
gov_fed <- subset(x = rbind(tp1,tp2,tp3,tp4,tp5,tp6))
View(gov_fed)
gov_fed <- subset(x = rbind(tp1,tp2,tp3,tp4,tp5,tp6)) %>% filter(grep(textf, pattern = "governo federal"))
grep(tp1$textf, pattern = "governo federal")
gov_fed <- subset(x = rbind(tp1,tp2,tp3,tp4,tp5,tp6)) %>% filter(textf %like% "governo federal")
gov_fed <- gov_fed[grep(gov_fed, pattern = "governo federal"),]
gov_fed <- subset(x = rbind(tp1,tp2,tp3,tp4,tp5,tp6))
gov_fed <- subset(x = rbind(tp1,tp2,tp3,tp4,tp5,tp6))
gov_fed <- gov_fed[grep(gov_fed$tweet, pattern = "governo federal"),]
grep(gov_fed$tweet, pattern = "governo federal"),
grep(gov_fed$tweet, pattern = "governo federal")
gov_fed <- subset(x = rbind(tp1,tp2,tp3,tp4,tp5,tp6))
gov_fed <- gov_fed[grep(gov_fed$textf, pattern = "governo federal"),]
grep(gov_fed$textf, pattern = "governo federal")
View(gov_fed)
get_freq(gov_fed, cloud_max_words = ncloud)
gov_fed <- subset(x = rbind(tp1,tp2,tp3,tp4,tp5,tp6))
gov_fed <- gov_fed[grep(gov_fed$textf, pattern = "federal") | grep(gov_fed$textf, pattern = "governo"),]
gov_fed <- gov_fed[grep(gov_fed$textf, pattern = "governo|federal"),]
gov_fed <- subset(x = rbind(tp1,tp2,tp3,tp4,tp5,tp6))
gov_fed <- gov_fed[grep(gov_fed$textf, pattern = "(governo)|(federal)"),]
get_freq(gov_fed, cloud_max_words = ncloud)
get_freq(gov_fed, cloud_max_words = ncloud)
col_posneg <- c(9:11)
pos_neg <- df[col_posneg,]
df <- matrix(c(colSums(tp1.s>0),colSums(tp2.s>0),colSums(tp3.s>0),colSums(tp4.s>0),colSums(tp5.s>0),colSums(tp6.s>0)), nrow = 11, ncol = 6, byrow = F)
pos_neg <- df[col_posneg,]
View(pos_neg)
aux <- pos_neg
for (i in c(1:length(pos_neg[1,]))) {
for (j in c(1:length(pos_neg[,1]))) {
pos_neg[j,i] <- (pos_neg[j,i]/ sum(aux[,i]))*100
}
}
View(df)
tp_govf <- get_sentiment(gov_fed$textf, "Sentimentos Maio 2020")
df_gov <- matrix(c(colSums(tp_govf>0)), nrow = 11, ncol = 1, byrow = F)
View(df_gov)
tp_govf <- get_sentiment(gov_fed$textf, "Sentimentos Maio 2020")
df_gov <- matrix(c(colSums(tp_govf>0)), nrow = 11, ncol = 1, byrow = F)
col_posneg <- c(9:11)
pos_neg <- df_gov[col_posneg,]
aux <- pos_neg
for (i in c(1:length(pos_neg[1,]))) {
for (j in c(1:length(pos_neg[,1]))) {
pos_neg[j,i] <- (pos_neg[j,i]/ sum(aux[,i]))*100
}
}
sent <- df_gov[c(col_sents),]
barplot(pos_neg, col=rainbow(length(pos_neg[,1])), names.arg = months, beside = T, xlab = "Mês", ylab="Percentual(%)", main= "Sentimentos positivos e negativos no período de pesquisa")
legend("topright", pch = 15, col = rainbow(length(pos_neg[,1])), sent_labels[col_posneg], cex = 0.75)
tp_govf <- get_sentiment(gov_fed$textf, "Sentimentos Maio 2020")
tp_govf <- get_sentiment(gov_fed$textf, "Sentimentos Maio 2020")
df_gov <- matrix(c(colSums(tp_govf>0)), nrow = 11, ncol = 1, byrow = F)
col_posneg <- c(9:11)
pos_neg <- df_gov[col_posneg,]
aux <- pos_neg
for (i in c(1:length(pos_neg[1,]))) {
for (j in c(1:length(pos_neg[,1]))) {
pos_neg[j,i] <- (pos_neg[j,i]/ sum(aux[,i]))*100
}
}
length(pos_neg[1,]
length(pos_neg[1,])
length(pos_neg[1,])
pos_neg <- df_gov[col_posneg,]
aux <- pos_neg
for (i in c(1:length(pos_neg[1,]))) {
for (j in c(1:length(pos_neg[,1]))) {
pos_neg[j,i] <- (pos_neg[j,i]/ sum(aux[,i]))*100
}
}
pos_neg <- df_gov[col_posneg,]
pos_neg
length(pos_neg[,1])
for (j in c(1:length(pos_neg))) {
pos_neg[j] <- (pos_neg[j]/ sum(aux))*100
}
pos_neg
tp_govf <- get_sentiment(gov_fed$textf, "Sentimentos Maio 2020")
df_gov <- matrix(c(colSums(tp_govf>0)), nrow = 11, ncol = 1, byrow = F)
col_posneg <- c(9:11)
pos_neg <- df_gov[col_posneg,]
aux <- pos_neg
for (j in c(1:length(pos_neg))) {
pos_neg[j] <- (pos_neg[j]/ sum(aux))*100
}
sent <- df_gov[c(col_sents),]
barplot(pos_neg, col=rainbow(length(pos_neg[,1])), names.arg = months, beside = T, xlab = "Mês", ylab="Percentual(%)", main= "Sentimentos positivos e negativos no período de pesquisa")
legend("topright", pch = 15, col = rainbow(length(pos_neg[,1])), sent_labels[col_posneg], cex = 0.75)
barplot(matrix(pos_neg, nrow = 3, ncol = 1) , col=rainbow(length(pos_neg[,1])), names.arg = months, beside = T, xlab = "Mês", ylab="Percentual(%)", main= "Sentimentos positivos e negativos no período de pesquisa")
barplot(pos_neg, col=rainbow(length(pos_neg[,1])), names.arg = months, beside = T, xlab = "Mês", ylab="Percentual(%)", main= "Sentimentos positivos e negativos no período de pesquisa")
barplot(pos_neg, col=rainbow(length(pos_neg)), names.arg = months, beside = T, xlab = "Mês", ylab="Percentual(%)", main= "Sentimentos positivos e negativos no período de pesquisa")
barplot(pos_neg, col=rainbow(length(pos_neg)), names.arg = c("Negativo, Positivo, Neutro"), beside = T, xlab = "Mês", ylab="Percentual(%)", main= "Sentimentos positivos e negativos no período de pesquisa")
barplot(pos_neg, col=rainbow(length(pos_neg)), names.arg = c("Negativo"," Positivo", "Neutro"), beside = T, xlab = "Mês", ylab="Percentual(%)", main= "Sentimentos positivos e negativos no período de pesquisa")
barplot(pos_neg, col=rainbow(length(pos_neg)), names.arg = c("Negativo","Positivo", "Neutro"), beside = T, xlab = "Mês", ylab="Percentual(%)", main= "Sentimentos positivos e negativos no período de pesquisa")
barplot(pos_neg, col=rainbow(length(pos_neg)), names.arg = c("Negativo","Positivo", "Neutro"), beside = T, xlab = "Mês", ylab="Percentual(%)", main= "Sentimentos positivos e negativos sobre \"Governo Federal\"")

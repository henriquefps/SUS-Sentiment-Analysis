bilan <- aggregate(cbind(cond_A,cond_B,cond_C)~specie , data=data , mean)
bilan
rownames(bilan) <- bilan[,1]
bilan
#Let's calculate the average value for each condition and each specie with the *aggregate* function
bilan <- aggregate(cbind(cond_A,cond_B,cond_C)~specie , data=data , mean)
bilan
rownames(bilan) <- bilan[,1]
bilan
#Let's calculate the average value for each condition and each specie with the *aggregate* function
bilan <- aggregate(cbind(cond_A,cond_B,cond_C)~specie , data=data , mean)
View(bilan)
data <- data.frame(
specie=c(rep("sorgho" , 10) , rep("poacee" , 10) ),
cond_A=rnorm(20,10,4),
cond_B=rnorm(20,8,3),
cond_C=rnorm(20,5,4)
)
#Let's calculate the average value for each condition and each specie with the *aggregate* function
bilan <- aggregate(cbind(cond_A,cond_B,cond_C)~specie , data=data , mean)
View(bilan)
#Let's calculate the average value for each condition and each specie with the *aggregate* function
bilan <- aggregate(cbind(cond_A,cond_B,cond_C) , data=data , mean)
#Let's calculate the average value for each condition and each specie with the *aggregate* function
bilan <- aggregate(cbind(cond_A,cond_B,cond_C)~specie , data=data , mean)
View(data)
bilan[,1]
bilan
rownames(bilan) <- bilan[,1]
as.matrix(bilan[,-1])
bilan <- as.matrix(bilan[,-1])
df <- data.frame(a=MRT_1F,
b= MRT_3F,
c=MRT_5F,
d= MRT_10F,
e=MRT_15F,
f=MRT_sem_F,
row.names = clock)
df <- as.data.frame(t(as.matrix(df)))
clock
#Let's calculate the average value for each condition and each specie with the *aggregate* function
bilan <- cbind(MRT_sem_F,MRT_1F)~clock
bilan
bilan
matrix(c(MRT_1F,MRT_3F,MRT_5F,MRT_10F,MRT_15F,MRT_sem_F),nrow = 6, ncol = 7)
matrix(c(MRT_1F,MRT_3F,MRT_5F,MRT_10F,MRT_15F,MRT_sem_F),nrow = 7, ncol = 6)
matrix(c(MRT_1F,MRT_3F,MRT_5F,MRT_10F,MRT_15F,MRT_sem_F),nrow = 7, ncol = 6, byrow = T)
6
matrix(c(MRT_1F,MRT_3F,MRT_5F,MRT_10F,MRT_15F,MRT_sem_F),nrow = 6, ncol = 7)
matrix(c(MRT_1F,MRT_3F,MRT_5F,MRT_10F,MRT_15F,MRT_sem_F),nrow = 6, ncol = 7)
t(matrix(c(MRT_1F,MRT_3F,MRT_5F,MRT_10F,MRT_15F,MRT_sem_F),nrow = 6, ncol = 7))
matrix(c(MRT_1F,MRT_3F,MRT_5F,MRT_10F,MRT_15F,MRT_sem_F),nrow = 6, ncol = 7, byrow = T)
#I am ready to add the error bar on the plot using my "error bar" function !
barplot(df , beside=T , legend.text=T,col=c("blue" , "skyblue") , ylim=c(0,lim) , ylab="height")
df <- matrix(c(MRT_1F,MRT_3F,MRT_5F,MRT_10F,MRT_15F,MRT_sem_F),nrow = 6, ncol = 7, byrow = T)
#I am ready to add the error bar on the plot using my "error bar" function !
barplot(df , beside=T , legend.text=T,col=c("blue" , "skyblue") , ylim=c(0,lim) , ylab="height")
#I am ready to add the error bar on the plot using my "error bar" function !
barplot(df , beside=T , legend.text=T,col=c("blue" , "skyblue")
#I am ready to add the error bar on the plot using my "error bar" function !
barplot(df , beside=T , legend.text=T,col=c("blue" , "skyblue")  )
, ylab="height"
#I am ready to add the error bar on the plot using my "error bar" function !
barplot(df , beside=T , legend.text=T,col=c("blue" , "skyblue")  , ylab="height")
#I am ready to add the error bar on the plot using my "error bar" function !
barplot(df[,c(1,6)] , beside=T , legend.text=T,col=c("blue" , "skyblue")  , ylab="height")
df
#I am ready to add the error bar on the plot using my "error bar" function !
barplot(df[c(1,6),] , beside=T , legend.text=T,col=c("blue" , "skyblue")  , ylab="height")
#I am ready to add the error bar on the plot using my "error bar" function !
barplot(df[c(1,6),] , beside=T , legend.text=T,col=c("blue" , "skyblue")  , ylab="height", log = T)
#I am ready to add the error bar on the plot using my "error bar" function !
barplot(df[c(1,6),] , beside=T , legend.text=T,col=c("blue" , "skyblue")  , ylab="height", log = T)
p<- barplot(df[c(1,6),] , beside=T , legend.text=T,col=c("blue" , "skyblue")  , ylab="height", log = T)
p<- barplot(df[c(1,6),] , beside=T , legend.text=T,col=c("blue" , "skyblue")  , ylab="height")
require(scales)
p + scale_y_continuous(trans = log2_trans(),
breaks = trans_breaks("log2", function(x) 2^x),
labels = trans_format("log2", math_format(2^.x)))
p<- barplot(df[c(1,6),] , beside=T , legend.text=T,col=c("blue" , "skyblue")  , ylab="height")
require(scales)
p + scale_y_continuous(trans = "log10")
sp + scale_y_continuous(trans='log2')
#I am ready to add the error bar on the plot using my "error bar" function !
sp<- barplot(df[c(1,6),] , beside=T , legend.text=T,col=c("blue" , "skyblue")  , ylab="height")
sp + scale_y_continuous(trans='log2')
sp + scale_y_continuous(trans='log10')
sp<- barplot(df[c(1,6),] , beside=T , legend.text=T,col=c("blue" , "skyblue")  , ylab="height")
sp + scale_y_continuous(trans='log10')
sp + scale_y_continuous(trans='log10')
sp + scale_y_continuous(trans='log10')
#I am ready to add the error bar on the plot using my "error bar" function !
sp <- barplot(df[c(1,6),] , beside=T , legend.text=T,col=c("blue" , "skyblue")  , ylab="height")
sp
sp + scale_y_continuous(trans='log10')
sp
sp <- sp + scale_y_continuous(trans='log10')
sp
library(scales)
#I am ready to add the error bar on the plot using my "error bar" function !
sp <- barplot(df[c(1,6),] , beside=T , legend.text=T,col=c("blue" , "skyblue")  , ylab="height")
sp + scale_y_continuous(trans='log10')
library(MASS) # to access Animals data sets
library(scales) # to access break formatting functions
# x and y axis are transformed and formatted
p2 <- ggplot(Animals, aes(x = body, y = brain)) + geom_point() +
scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
theme_bw()
p2
# x and y axis are transformed and formatted
p2 <- barplot(Animals, aes(x = body, y = brain)) + geom_point() +
scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
theme_bw()
# x and y axis are transformed and formatted
p2 <- barplot(df[c(1,6),], aes(x = body, y = brain)) + geom_point() +
scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
theme_bw()
# x and y axis are transformed and formatted
p2 <- barplot(df[c(1,6),], beside = T) + geom_point() +
scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
theme_bw()
ggplot(df[c(1,6),], aes(x=clarity, fill=cut)) +
geom_bar() +
coord_trans(ytrans="log10")
df <- data.frame(elements=c("A", "B", "C", "D", "E"),
c= c(5,7,12,15,10))
df
summary(df)
var(df)
df <- data.frame(elements=c("A", "B", "C", "D", "E"),
X= c(5,7,12,15,10))
df
summary(df)
var(df$c)
var(df$x)
var(df)
?var
var(df$x)
sd(df)
sd(df$X)
var(df)
var(df$X)
sd(df$X)
length(which(df$X) % 2 == 0)/nrow(df)
length(which(df$X)%2 == 0)/nrow(df)
length(which(df$X)%%2 == 0)/nrow(df)
length(which(df$X%%2 == 0))/nrow(df)
sd <-4250
erro <-300
nc<-(1-0.9)/2
n <-((qnorm(nc,lower.tail= F)*sd)/erro)^2
n
"
sd <- 4.1681
N <- 2637
erro <- 1
nc <- (1-0.95)/2
n <-(qnorm(nc, lower.tail= F)^2 * sd^2 * N)/((erro^2*(N-1))+(qnorm(nc,lower.tail = F)^2*sd^2))
n
sd <-6250
erro <-500
nc<-(1-0.95)/2
n <-((qnorm(nc,lower.tail= F)*sd)/erro)^2
n"
sd <-4250
erro <-300
nc<-(1-0.9)/2
n <-((qnorm(nc,lower.tail= F)*sd)/erro)^2
n
sd <- 5
N <- 1500
erro <- 1.5
nc <- (1-0.955)/2
n <-(qnorm(nc, lower.tail= F)^2 * sd^2 * N)/((erro^2*(N-1))+(qnorm(nc,lower.tail = F)^2*sd^2))
n
sd <- (30-10)/4
erro <- 1
nc <- (1-0.98)/2
n <-((qnorm(nc,lower.tail= F)*sd)/erro)^2
n
sd <- (30-10)/4
N <- 5000
erro <- 1
nc <- (1-0.98)/2
n <-(qnorm(nc, lower.tail= F)^2 * sd^2 * N)/((erro^2*(N-1))+(qnorm(nc,lower.tail = F)^2*sd^2))
n
pnorm(q=30,mean =  50,sd =  10)
1-pnorm(q=30,mean =  50,sd =  10)
pnorm(q=30,mean =  50,sd =  10)
qnorm(q=30,mean =  50,sd =  10)
rnorm()
rnorm(100)
pnorm(1)
pnorm(1)-pnorm(1, lower.tail = F)
1-pnorm(1)-pnorm(1)
1-pnorm(1)-pnorm(1,lower.tail = F)
pnorm(1)-1+pnorm(1)
pnorm(1)
1-pnorm(-2)
pnorm(1)
1-pnorm(-2)
1-pnorm(1)
pnorm(-2)
pnorm(0)
1-pnorm(1.28)
pnorm(mean = 90, sd = 21)
qnorm(p = 0.90,mean = 90, sd = 21)
qnorm(p = 0.90,mean = 90, sd = 21, lower.tail = F)
#Desviopadrão
d <-3.8
#Médiadaamostra
x <-30.2
#Tamanhodaamostra
n <-100
#Nível de confiança
nc<-(1-0.95)/2
#Erro
error <-d/sqrt(n)
#Limiteinferior
left <-x-(qnorm(nc,lower.tail= F)*error)
#Limitesuperior
right <-x+(qnorm(nc,lower.tail= F)*error)>cat("[",left, "-", right,"]")
#Desviopadrão
d <-3.8
#Médiadaamostra
x <-30.2
#Tamanhodaamostra
n <-100
#Nível de confiança
nc<-(1-0.95)/2
#Erro
error <-d/sqrt(n)
#Limiteinferior
left <-x-(qnorm(nc,lower.tail= F)*error)
#Limitesuperior
right <-x+(qnorm(nc,lower.tail= F)*error)
cat("[",left, "-", right,"]")
#Desviopadrão
d <-47
#Médiadaamostra
x <-658
#Tamanhodaamostra
n <-100
#Nível de confiança
nc<-(1-0.90)/2
#Erro
error <-d/sqrt(n)
#Limiteinferior
left <-x-(qnorm(nc,lower.tail= F)*error)
#Limitesuperior
right <-x+(qnorm(nc,lower.tail= F)*error)
cat("[",left, "-", right,"]")
cat("[",left, "-", right,"]", sep = "")
aux <- c(4.37, 3.63, 2.78, 5.46, 2.18, 6.07, 3.24, 5.89, 4.86, 4.64)
sd(aux)
length(aux)
aux <- c(4.37, 3.63, 2.78, 5.46, 2.18, 6.07, 3.24, 5.89, 4.86, 4.64)
#Desviopadrão
d <-sd(aux)
#Médiadaamostra
x <-mean(aux)
#Tamanhodaamostra
n <-length(aux)
#Nível de confiança
nc<-(1-0.90)/2
#Erro
error <-d/sqrt(n)
#Limiteinferior
left <-x-(qnorm(nc,lower.tail= F)*error)
#Limitesuperior
right <-x+(qnorm(nc,lower.tail= F)*error)
cat("[",left, "-", right,"]", sep = "")
cat("[",left, "-", right,"]", sep = "")
setwd("~/GitHub/SUS-Sentiment-Analysis/Projeto")
library(tm)
library(wordcloud)
library(syuzhet)
library(stringr)
library(stringi)
library(readr)
library(dplyr)
tweets <- read.csv("tweetsdb.csv", encoding = "UTF-8")
tweets <- tweets[tweets$retweet == "False",]
tweets$date <- str_extract(tweets$date, "[0-9]{4}-[0-9]{2}")
tweets$textf <- textclean1(tweets$tweet)
textclean1 <- function(text_list){
aux <- text_list
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
aux <-  readr::parse_character(aux, locale = readr::locale('pt'))
aux <- sapply(aux, function(x) stri_trans_tolower(x,'pt')) # Por tudo em letras minúsculas
aux <- gsub("<[Uu]\\+[a-zA-Z0-9]*>", "",  aux); # Remover Emojis
aux <- gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "",  aux);
aux <- str_replace(aux,"RT @[a-z,A-Z]*: ","")
aux <- gsub("@\\w+", "", aux)
aux <- removeURL(aux)
aux <- str_replace_all(aux,"@[a-zA-Z]*","") # Remover marcações @username
aux <- gsub("[^[:alnum:][:blank:]!?]", "", aux)
aux <- gsub("[[:digit:]]", "", aux)
return(aux)
}
build_corpus <- function(text_listf, rwords=NULL){
tweets_t <- paste(text_listf,collapse=" ")
tweets_S <- VectorSource(tweets_t)
corpus <- Corpus(tweets_S)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("portuguese"))
corpus <- tm_map(corpus, removeWords, rwords)
return(corpus)
}
get_sentiment <- function(text_listf, title="Sentimentos"){
s <- get_nrc_sentiment(text_listf, language = "portuguese")
s$neutral <- (s$positive == s$negative)>0
s$positive <- (s$positive > s$negative)>0
s$negative <- (s$positive == 0 & s$neutral == 0)>0
colnames(s) <- sent_labels
barplot(colSums(s),las=2,col=rainbow(10), ylab= "Quantidade",
main=title)
return(s)
}
get_freq <- function(text_listf, rwords=NULL, cloud_max_words = 100){
corpus <- build_corpus(text_listf, rwords)
dtm <-TermDocumentMatrix(corpus)
dtm <- as.matrix(dtm)
fre <- sort(rowSums(dtm),decreasing=TRUE)
wordcloud(names(fre),freq=fre,min.freq=1,max.words=cloud_max_words,scale=c(4,.5),
random.order=F, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
return(fre)
}
tweets <- read.csv("tweetsdb.csv", encoding = "UTF-8")
tweets <- tweets[tweets$retweet == "False",]
tweets$date <- str_extract(tweets$date, "[0-9]{4}-[0-9]{2}")
tweets$textf <- textclean1(tweets$tweet)
tweets <- read.csv("tweetsdb.csv", encoding = "UTF-8")
tweets <- tweets[tweets$retweet == "False",]
tweets$date <- str_extract(tweets$date, "[0-9]{4}-[0-9]{2}")
tweets$textf <- textclean1(tweets$tweet)
library(tm)
library(wordcloud)
library(syuzhet)
library(stringr)
library(stringi)
library(readr)
library(dplyr)
setwd("~/GitHub/SUS-Sentiment-Analysis/Projeto")
sent_labels <- c("Raiva", "Antecipação", "Nojo", "Medo", "Alegria",
"Tristeza", "Surpesa", "Confiança", "Negativo", "Positivo", "Neutral")
months <- c("Dez 2019", "Jan 2020", "Fev 2020", "Mar 2020", "Abril 2020",
"Maio 2020")
aux <- str_extract(string = tweets$tweet, pattern = "[A-Za-z]*n ")
aux <- aux[!is.na(aux)]
aux <- gsub(x = unique(aux), pattern =  " ", replacement =  "")
head((tweets %>% select(id, date, tweet, textf)), n = 10)
aux <- str_extract(string = tweets$tweet, pattern = "[A-Za-z]*n ")
aux <- aux[!is.na(aux)]
aux <- gsub(x = unique(aux), pattern =  " ", replacement =  "")
head((tweets %>% select(id, date, tweet, textf)), n = 10)
aux <- str_extract(string = tweets$tweet, pattern = "[A-Za-z]*n ")
aux <- aux[!is.na(aux)]
aux <- gsub(x = unique(aux), pattern =  " ", replacement =  "")
head((tweets %>% select(id, date, tweet, textf)), n = 10)
aux
[181] "Bjin"            "dersen"          "empezaron"       "Brown"           "Eran"            "Cedan"
gsub(x=s, pattern = "\[[0-9]*\]")
gsub(x=s, pattern = "\\[[0-9]*\\]")
gsub(x=s, pattern = "\\[[0-9]*\\]", replacement = "")
[157] "siguen"          "gadominion"      "mmn"             "sobran"          "TeichNelson"     "Lockdown"
[223] "tomasfeuermann"  "Hoffman"         "salen"           "usan"            "Lan"'
'
s <- gsub(x=s, pattern = "\\[[0-9]*\\]", replacement = "")
'
gsub(x=s, pattern = "\\[[0-9]*\\]", replacement = "")
'
s <- '[1] "con"             "Protejan"        "Bon"             "compren"         "Denatran"        "Tan"
s <- '[1] "con""Protejan""Bon""compren" "Denatran""Tan"
s <- '[1] "con""Protejan""Bon""compren" "Denatran""Tan"
s <- '[1] "con""Protejan""Bon""compren" "Denatran""Tan"
s <- '[1] "con""Protejan""Bon""compren" "Denatran""Tan"
[7] "enviaron""lan""eran" "n"  "en" "mueren"
[13] "sejan""Ainnn""hajapacien""Bauman""veillon" "Irun"
s <- '[1] \"con\"\"Protejan\"\"Bon\"\"compren\" \"Denatran\"\"Tan\"
s <- '[1] \"con\"\"Protejan\"\"Bon\"\"compren\" \"Denatran\"\"Tan\"   [7] \"enviaron\"\"lan\"\"eran\" \"n\"  \"en\" \"mueren\"  [13] \"sejan\"\"Ainnn\"\"hajapacien\"\"Bauman\"\"veillon\" \"Irun\" [19] \"implanon\"\"John\" \"min\"\"Jeanzin\" \"quieren\" \"dersin\"  [25] \"Man\"\"rebelan\" \"cn\" \"man\"\"fan\"\"han\"  [31] \"repiten\" \"sen\"\"Wn\" \"midan\"\"Nn\" \"Minion\"  [37] \"Axon\" \"contaron\"\"Brunin\"\"ErickBrianColon\" \"Brian\"\"penn\" [43] \"Florian\" \"nn\" \"dedin\"\"son\"\"Con\"\"presuman\"  [49] \"yan\"\"Ninguen\" \"un\" \"bolsominion\"\"cawen\"\"Dan\"  [55] \"escribieron\"\"Saben\"\"Hamon\"\"Pokemon\" \"pasan\"\"dangerdirection\" [61] \"dicen\"\"an\" \"van\"\"vmin\" \"finn\" \"jn\" [67] \"roacutan\"\"vitin\"\"Aerolin\" \"borraron\"\"Aeron\"\"Waldman\" [73] \"IrvingChillon\"   \"version\" \"Motivacion\"\"seran\"\"ntgen\"\"Ederson\" [79] \"hein\" \"weon\" \"Jacson\"\"veron\"\"deforman\"\"tan\"  [85] \"Luan\" \"revelan\" \"MongeHan\"\"Einstein\"\"Van\"\"in\" [91] \"legraton\"\"jeongin\" \"bolsomion\" \"shaman\"\"bailan\"\"Tofen\" [97] \"ainsten\" \"AlbertEinstein\"  \"Klan\" \"sobren\"\"Bjorn\"\"jonathan\" [103] \"fin\"\"discuten\"\"Jean\" \"Admin\"\"Ainn\" \"Un\"[109] \"suban\"\"Buscopan\"\"hudson\"\"nenein\"\"canarin\" \"Rainan\" [115] \"Muhsin\"\"American\"\"garsan\"\"Ain\"\"hayinnnnnnnnn\"   \"reclaman\" [121] \"buscopan\"\"inviten\" \"estaban\" \"liberteen\" \"naman\"\"dan\" [127] \"fofin\"\"Leon\" \"iguin\"\"Butantan\"\"minion\"\"Jelipin\"[133] \"Quiten\"\"Huan\" \"mimarisin\" \"pedrowestphalen\" \"AnneGonn\"\"heineken\" [139] \"Westphalen\"\"duran\"\"detran\"\"preparen\"\"rakin\"\"Wilson\" [145] \"neguin\"\"den\"\"Association\"\"graban\"\"valgan\"\"gustan\" [151] \"Sen\"\"merlin\"\"haechan\" \"pusieron\"\"Ken\"\"infringen\"[157] \"siguen\"\"gadominion\"\"mmn\"\"sobran\"\"TeichNelson\"\"Lockdown\" [163] \"Nelson\"\"Watson\"\"Justin\"\"nelson\"\"tahan\"\"Amazon\" [169] \"hechan\"\"Ewan\" \"Jordan\"\"Allan\"\"lockdown\"\"Johnson\"[175] \"sacaron\" \"can\"\"Morgan\"\"richarlisson\"    \"verifiquen\"\"Verifiquen\"[181] \"Bjin\" \"dersen\"\"empezaron\" \"Brown\"\"Eran\" \"Cedan\"[187] \"Suban\"\"Edilson\" \"manden\"\"faltan\"\"Ubiratan\"\"sorrisin\" [193] \"Wanderson\" \"Fran\" \"assumption\"\"maaaaan\" \"zen\"\"einstein\" [199] \"Mandan\"\"tiren\"\"En\" \"difundan\"\"respetan\"\"muestren\" [205] \"Patterson\" \"Jarun\"\"salgan\"\"Estaban\" \"LockDown\"\"aminin\" [211] \"chingdizon\"\"compartan\" \"Pongan\"\"borren\"\"acabaron\"\"Iguin\"[217] \"cierren\" \"significan\"\"TlalpanConscien\" \"falten\"\"encantan\"\"olvidaron\"[223] \"tomasfeuermann\"  \"Hoffman\" \"salen\"\"usan\" \"Lan\"'
s <- "[1] \"con\"\"Protejan\"\"Bon\"\"compren\" \"Denatran\"\"Tan\"   [7] \"enviaron\"\"lan\"\"eran\" \"n\"  \"en\" \"mueren\"  [13] \"sejan\"\"Ainnn\"\"hajapacien\"\"Bauman\"\"veillon\" \"Irun\" [19] \"implanon\"\"John\" \"min\"\"Jeanzin\" \"quieren\" \"dersin\"  [25] \"Man\"\"rebelan\" \"cn\" \"man\"\"fan\"\"han\"  [31] \"repiten\" \"sen\"\"Wn\" \"midan\"\"Nn\" \"Minion\"  [37] \"Axon\" \"contaron\"\"Brunin\"\"ErickBrianColon\" \"Brian\"\"penn\" [43] \"Florian\" \"nn\" \"dedin\"\"son\"\"Con\"\"presuman\"  [49] \"yan\"\"Ninguen\" \"un\" \"bolsominion\"\"cawen\"\"Dan\"  [55] \"escribieron\"\"Saben\"\"Hamon\"\"Pokemon\" \"pasan\"\"dangerdirection\" [61] \"dicen\"\"an\" \"van\"\"vmin\" \"finn\" \"jn\" [67] \"roacutan\"\"vitin\"\"Aerolin\" \"borraron\"\"Aeron\"\"Waldman\" [73] \"IrvingChillon\"   \"version\" \"Motivacion\"\"seran\"\"ntgen\"\"Ederson\" [79] \"hein\" \"weon\" \"Jacson\"\"veron\"\"deforman\"\"tan\"  [85] \"Luan\" \"revelan\" \"MongeHan\"\"Einstein\"\"Van\"\"in\" [91] \"legraton\"\"jeongin\" \"bolsomion\" \"shaman\"\"bailan\"\"Tofen\" [97] \"ainsten\" \"AlbertEinstein\"  \"Klan\" \"sobren\"\"Bjorn\"\"jonathan\" [103] \"fin\"\"discuten\"\"Jean\" \"Admin\"\"Ainn\" \"Un\"[109] \"suban\"\"Buscopan\"\"hudson\"\"nenein\"\"canarin\" \"Rainan\" [115] \"Muhsin\"\"American\"\"garsan\"\"Ain\"\"hayinnnnnnnnn\"   \"reclaman\" [121] \"buscopan\"\"inviten\" \"estaban\" \"liberteen\" \"naman\"\"dan\" [127] \"fofin\"\"Leon\" \"iguin\"\"Butantan\"\"minion\"\"Jelipin\"[133] \"Quiten\"\"Huan\" \"mimarisin\" \"pedrowestphalen\" \"AnneGonn\"\"heineken\" [139] \"Westphalen\"\"duran\"\"detran\"\"preparen\"\"rakin\"\"Wilson\" [145] \"neguin\"\"den\"\"Association\"\"graban\"\"valgan\"\"gustan\" [151] \"Sen\"\"merlin\"\"haechan\" \"pusieron\"\"Ken\"\"infringen\"[157] \"siguen\"\"gadominion\"\"mmn\"\"sobran\"\"TeichNelson\"\"Lockdown\" [163] \"Nelson\"\"Watson\"\"Justin\"\"nelson\"\"tahan\"\"Amazon\" [169] \"hechan\"\"Ewan\" \"Jordan\"\"Allan\"\"lockdown\"\"Johnson\"[175] \"sacaron\" \"can\"\"Morgan\"\"richarlisson\"    \"verifiquen\"\"Verifiquen\"[181] \"Bjin\" \"dersen\"\"empezaron\" \"Brown\"\"Eran\" \"Cedan\"[187] \"Suban\"\"Edilson\" \"manden\"\"faltan\"\"Ubiratan\"\"sorrisin\" [193] \"Wanderson\" \"Fran\" \"assumption\"\"maaaaan\" \"zen\"\"einstein\" [199] \"Mandan\"\"tiren\"\"En\" \"difundan\"\"respetan\"\"muestren\" [205] \"Patterson\" \"Jarun\"\"salgan\"\"Estaban\" \"LockDown\"\"aminin\" [211] \"chingdizon\"\"compartan\" \"Pongan\"\"borren\"\"acabaron\"\"Iguin\"[217] \"cierren\" \"significan\"\"TlalpanConscien\" \"falten\"\"encantan\"\"olvidaron\"[223] \"tomasfeuermann\"  \"Hoffman\" \"salen\"\"usan\" \"Lan\""
gsub(x=s, pattern = "\\[[0-9]*\\]", replacement = )
gsub(x=s, pattern = "\\[[0-9]*\\]", replacement = "")
s <- " \"con\"\"Protejan\"\"Bon\"\"compren\" \"Denatran\"\"Tan\"    \"enviaron\"\"lan\"\"eran\" \"n\"  \"en\" \"mueren\"   \"sejan\"\"Ainnn\"\"hajapacien\"\"Bauman\"\"veillon\" \"Irun\"  \"implanon\"\"John\" \"min\"\"Jeanzin\" \"quieren\" \"dersin\"   \"Man\"\"rebelan\" \"cn\" \"man\"\"fan\"\"han\"   \"repiten\" \"sen\"\"Wn\" \"midan\"\"Nn\" \"Minion\"   \"Axon\" \"contaron\"\"Brunin\"\"ErickBrianColon\" \"Brian\"\"penn\"  \"Florian\" \"nn\" \"dedin\"\"son\"\"Con\"\"presuman\"   \"yan\"\"Ninguen\" \"un\" \"bolsominion\"\"cawen\"\"Dan\"   \"escribieron\"\"Saben\"\"Hamon\"\"Pokemon\" \"pasan\"\"dangerdirection\"  \"dicen\"\"an\" \"van\"\"vmin\" \"finn\" \"jn\"  \"roacutan\"\"vitin\"\"Aerolin\" \"borraron\"\"Aeron\"\"Waldman\"  \"IrvingChillon\"   \"version\" \"Motivacion\"\"seran\"\"ntgen\"\"Ederson\"  \"hein\" \"weon\" \"Jacson\"\"veron\"\"deforman\"\"tan\"   \"Luan\" \"revelan\" \"MongeHan\"\"Einstein\"\"Van\"\"in\"  \"legraton\"\"jeongin\" \"bolsomion\" \"shaman\"\"bailan\"\"Tofen\"  \"ainsten\" \"AlbertEinstein\"  \"Klan\" \"sobren\"\"Bjorn\"\"jonathan\"  \"fin\"\"discuten\"\"Jean\" \"Admin\"\"Ainn\" \"Un\" \"suban\"\"Buscopan\"\"hudson\"\"nenein\"\"canarin\" \"Rainan\"  \"Muhsin\"\"American\"\"garsan\"\"Ain\"\"hayinnnnnnnnn\"   \"reclaman\"  \"buscopan\"\"inviten\" \"estaban\" \"liberteen\" \"naman\"\"dan\"  \"fofin\"\"Leon\" \"iguin\"\"Butantan\"\"minion\"\"Jelipin\" \"Quiten\"\"Huan\" \"mimarisin\" \"pedrowestphalen\" \"AnneGonn\"\"heineken\"  \"Westphalen\"\"duran\"\"detran\"\"preparen\"\"rakin\"\"Wilson\"  \"neguin\"\"den\"\"Association\"\"graban\"\"valgan\"\"gustan\"  \"Sen\"\"merlin\"\"haechan\" \"pusieron\"\"Ken\"\"infringen\" \"siguen\"\"gadominion\"\"mmn\"\"sobran\"\"TeichNelson\"\"Lockdown\"  \"Nelson\"\"Watson\"\"Justin\"\"nelson\"\"tahan\"\"Amazon\"  \"hechan\"\"Ewan\" \"Jordan\"\"Allan\"\"lockdown\"\"Johnson\" \"sacaron\" \"can\"\"Morgan\"\"richarlisson\"    \"verifiquen\"\"Verifiquen\" \"Bjin\" \"dersen\"\"empezaron\" \"Brown\"\"Eran\" \"Cedan\" \"Suban\"\"Edilson\" \"manden\"\"faltan\"\"Ubiratan\"\"sorrisin\"  \"Wanderson\" \"Fran\" \"assumption\"\"maaaaan\" \"zen\"\"einstein\"  \"Mandan\"\"tiren\"\"En\" \"difundan\"\"respetan\"\"muestren\"  \"Patterson\" \"Jarun\"\"salgan\"\"Estaban\" \"LockDown\"\"aminin\"  \"chingdizon\"\"compartan\" \"Pongan\"\"borren\"\"acabaron\"\"Iguin\" \"cierren\" \"significan\"\"TlalpanConscien\" \"falten\"\"encantan\"\"olvidaron\" \"tomasfeuermann\"  \"Hoffman\" \"salen\"\"usan\" \"Lan\""
gsub
gsub(x=s, pattern = "\\\]", replacement = "")
gsub(x=s, pattern = "\\\"", replacement = "")
gsub(x=s, pattern = "\\\"", replacement = ",")
s <- gsub(x=s, pattern = "\\\"", replacement = ",")
gsub(x=s, pattern = " ", replacement = ",")
s <- gsub(x=s, pattern = " ", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
head((tweets %>% select(id, date, tweet, textf)), n = 10)
gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s
gsub(x=s, pattern = ",", replacement = "\",\"")
gsub(x=s, pattern = ",", replacement = "\",\"")
gsub(x=s, pattern = ",", replacement = '","')
gsub(x=s, pattern = ",", replacement = '","')
s <- gsub(x=s, pattern = "\\[[0-9]*\\]", replacement = "")
s <- " \"con\"\"Protejan\"\"Bon\"\"compren\" \"Denatran\"\"Tan\"    \"enviaron\"\"lan\"\"eran\" \"n\"  \"en\" \"mueren\"   \"sejan\"\"Ainnn\"\"hajapacien\"\"Bauman\"\"veillon\" \"Irun\"  \"implanon\"\"John\" \"min\"\"Jeanzin\" \"quieren\" \"dersin\"   \"Man\"\"rebelan\" \"cn\" \"man\"\"fan\"\"han\"   \"repiten\" \"sen\"\"Wn\" \"midan\"\"Nn\" \"Minion\"   \"Axon\" \"contaron\"\"Brunin\"\"ErickBrianColon\" \"Brian\"\"penn\"  \"Florian\" \"nn\" \"dedin\"\"son\"\"Con\"\"presuman\"   \"yan\"\"Ninguen\" \"un\" \"bolsominion\"\"cawen\"\"Dan\"   \"escribieron\"\"Saben\"\"Hamon\"\"Pokemon\" \"pasan\"\"dangerdirection\"  \"dicen\"\"an\" \"van\"\"vmin\" \"finn\" \"jn\"  \"roacutan\"\"vitin\"\"Aerolin\" \"borraron\"\"Aeron\"\"Waldman\"  \"IrvingChillon\"   \"version\" \"Motivacion\"\"seran\"\"ntgen\"\"Ederson\"  \"hein\" \"weon\" \"Jacson\"\"veron\"\"deforman\"\"tan\"   \"Luan\" \"revelan\" \"MongeHan\"\"Einstein\"\"Van\"\"in\"  \"legraton\"\"jeongin\" \"bolsomion\" \"shaman\"\"bailan\"\"Tofen\"  \"ainsten\" \"AlbertEinstein\"  \"Klan\" \"sobren\"\"Bjorn\"\"jonathan\"  \"fin\"\"discuten\"\"Jean\" \"Admin\"\"Ainn\" \"Un\" \"suban\"\"Buscopan\"\"hudson\"\"nenein\"\"canarin\" \"Rainan\"  \"Muhsin\"\"American\"\"garsan\"\"Ain\"\"hayinnnnnnnnn\"   \"reclaman\"  \"buscopan\"\"inviten\" \"estaban\" \"liberteen\" \"naman\"\"dan\"  \"fofin\"\"Leon\" \"iguin\"\"Butantan\"\"minion\"\"Jelipin\" \"Quiten\"\"Huan\" \"mimarisin\" \"pedrowestphalen\" \"AnneGonn\"\"heineken\"  \"Westphalen\"\"duran\"\"detran\"\"preparen\"\"rakin\"\"Wilson\"  \"neguin\"\"den\"\"Association\"\"graban\"\"valgan\"\"gustan\"  \"Sen\"\"merlin\"\"haechan\" \"pusieron\"\"Ken\"\"infringen\" \"siguen\"\"gadominion\"\"mmn\"\"sobran\"\"TeichNelson\"\"Lockdown\"  \"Nelson\"\"Watson\"\"Justin\"\"nelson\"\"tahan\"\"Amazon\"  \"hechan\"\"Ewan\" \"Jordan\"\"Allan\"\"lockdown\"\"Johnson\" \"sacaron\" \"can\"\"Morgan\"\"richarlisson\"    \"verifiquen\"\"Verifiquen\" \"Bjin\" \"dersen\"\"empezaron\" \"Brown\"\"Eran\" \"Cedan\" \"Suban\"\"Edilson\" \"manden\"\"faltan\"\"Ubiratan\"\"sorrisin\"  \"Wanderson\" \"Fran\" \"assumption\"\"maaaaan\" \"zen\"\"einstein\"  \"Mandan\"\"tiren\"\"En\" \"difundan\"\"respetan\"\"muestren\"  \"Patterson\" \"Jarun\"\"salgan\"\"Estaban\" \"LockDown\"\"aminin\"  \"chingdizon\"\"compartan\" \"Pongan\"\"borren\"\"acabaron\"\"Iguin\" \"cierren\" \"significan\"\"TlalpanConscien\" \"falten\"\"encantan\"\"olvidaron\" \"tomasfeuermann\"  \"Hoffman\" \"salen\"\"usan\" \"Lan\""
s <- gsub(x=s, pattern = "\\[[0-9]*\\]", replacement = "")
s <- gsub(x=s, pattern = "\\\"", replacement = ",")
s <- gsub(x=s, pattern = " ", replacement = ",")
s <- gsub(x=s, pattern = ",*", replacement = ",")
s <- gsub(x=s, pattern = "\\[[0-9]*\\]", replacement = "")
s <- " \"con\"\"Protejan\"\"Bon\"\"compren\" \"Denatran\"\"Tan\"    \"enviaron\"\"lan\"\"eran\" \"n\"  \"en\" \"mueren\"   \"sejan\"\"Ainnn\"\"hajapacien\"\"Bauman\"\"veillon\" \"Irun\"  \"implanon\"\"John\" \"min\"\"Jeanzin\" \"quieren\" \"dersin\"   \"Man\"\"rebelan\" \"cn\" \"man\"\"fan\"\"han\"   \"repiten\" \"sen\"\"Wn\" \"midan\"\"Nn\" \"Minion\"   \"Axon\" \"contaron\"\"Brunin\"\"ErickBrianColon\" \"Brian\"\"penn\"  \"Florian\" \"nn\" \"dedin\"\"son\"\"Con\"\"presuman\"   \"yan\"\"Ninguen\" \"un\" \"bolsominion\"\"cawen\"\"Dan\"   \"escribieron\"\"Saben\"\"Hamon\"\"Pokemon\" \"pasan\"\"dangerdirection\"  \"dicen\"\"an\" \"van\"\"vmin\" \"finn\" \"jn\"  \"roacutan\"\"vitin\"\"Aerolin\" \"borraron\"\"Aeron\"\"Waldman\"  \"IrvingChillon\"   \"version\" \"Motivacion\"\"seran\"\"ntgen\"\"Ederson\"  \"hein\" \"weon\" \"Jacson\"\"veron\"\"deforman\"\"tan\"   \"Luan\" \"revelan\" \"MongeHan\"\"Einstein\"\"Van\"\"in\"  \"legraton\"\"jeongin\" \"bolsomion\" \"shaman\"\"bailan\"\"Tofen\"  \"ainsten\" \"AlbertEinstein\"  \"Klan\" \"sobren\"\"Bjorn\"\"jonathan\"  \"fin\"\"discuten\"\"Jean\" \"Admin\"\"Ainn\" \"Un\" \"suban\"\"Buscopan\"\"hudson\"\"nenein\"\"canarin\" \"Rainan\"  \"Muhsin\"\"American\"\"garsan\"\"Ain\"\"hayinnnnnnnnn\"   \"reclaman\"  \"buscopan\"\"inviten\" \"estaban\" \"liberteen\" \"naman\"\"dan\"  \"fofin\"\"Leon\" \"iguin\"\"Butantan\"\"minion\"\"Jelipin\" \"Quiten\"\"Huan\" \"mimarisin\" \"pedrowestphalen\" \"AnneGonn\"\"heineken\"  \"Westphalen\"\"duran\"\"detran\"\"preparen\"\"rakin\"\"Wilson\"  \"neguin\"\"den\"\"Association\"\"graban\"\"valgan\"\"gustan\"  \"Sen\"\"merlin\"\"haechan\" \"pusieron\"\"Ken\"\"infringen\" \"siguen\"\"gadominion\"\"mmn\"\"sobran\"\"TeichNelson\"\"Lockdown\"  \"Nelson\"\"Watson\"\"Justin\"\"nelson\"\"tahan\"\"Amazon\"  \"hechan\"\"Ewan\" \"Jordan\"\"Allan\"\"lockdown\"\"Johnson\" \"sacaron\" \"can\"\"Morgan\"\"richarlisson\"    \"verifiquen\"\"Verifiquen\" \"Bjin\" \"dersen\"\"empezaron\" \"Brown\"\"Eran\" \"Cedan\" \"Suban\"\"Edilson\" \"manden\"\"faltan\"\"Ubiratan\"\"sorrisin\"  \"Wanderson\" \"Fran\" \"assumption\"\"maaaaan\" \"zen\"\"einstein\"  \"Mandan\"\"tiren\"\"En\" \"difundan\"\"respetan\"\"muestren\"  \"Patterson\" \"Jarun\"\"salgan\"\"Estaban\" \"LockDown\"\"aminin\"  \"chingdizon\"\"compartan\" \"Pongan\"\"borren\"\"acabaron\"\"Iguin\" \"cierren\" \"significan\"\"TlalpanConscien\" \"falten\"\"encantan\"\"olvidaron\" \"tomasfeuermann\"  \"Hoffman\" \"salen\"\"usan\" \"Lan\""
s <- gsub(x=s, pattern = "\\[[0-9]*\\]", replacement = "")
s <- gsub(x=s, pattern = "\\\"", replacement = ",")
s <- gsub(x=s, pattern = " ", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
,s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",", replacement = '","')
s <- gsub(x=s, pattern = "\\[[0-9]*\\]", replacement = "")
s <- gsub(x=s, pattern = "\\[[0-9]*\\]", replacement = "")
s <- " \"con\"\"Protejan\"\"Bon\"\"compren\" \"Denatran\"\"Tan\"    \"enviaron\"\"lan\"\"eran\" \"n\"  \"en\" \"mueren\"   \"sejan\"\"Ainnn\"\"hajapacien\"\"Bauman\"\"veillon\" \"Irun\"  \"implanon\"\"John\" \"min\"\"Jeanzin\" \"quieren\" \"dersin\"   \"Man\"\"rebelan\" \"cn\" \"man\"\"fan\"\"han\"   \"repiten\" \"sen\"\"Wn\" \"midan\"\"Nn\" \"Minion\"   \"Axon\" \"contaron\"\"Brunin\"\"ErickBrianColon\" \"Brian\"\"penn\"  \"Florian\" \"nn\" \"dedin\"\"son\"\"Con\"\"presuman\"   \"yan\"\"Ninguen\" \"un\" \"bolsominion\"\"cawen\"\"Dan\"   \"escribieron\"\"Saben\"\"Hamon\"\"Pokemon\" \"pasan\"\"dangerdirection\"  \"dicen\"\"an\" \"van\"\"vmin\" \"finn\" \"jn\"  \"roacutan\"\"vitin\"\"Aerolin\" \"borraron\"\"Aeron\"\"Waldman\"  \"IrvingChillon\"   \"version\" \"Motivacion\"\"seran\"\"ntgen\"\"Ederson\"  \"hein\" \"weon\" \"Jacson\"\"veron\"\"deforman\"\"tan\"   \"Luan\" \"revelan\" \"MongeHan\"\"Einstein\"\"Van\"\"in\"  \"legraton\"\"jeongin\" \"bolsomion\" \"shaman\"\"bailan\"\"Tofen\"  \"ainsten\" \"AlbertEinstein\"  \"Klan\" \"sobren\"\"Bjorn\"\"jonathan\"  \"fin\"\"discuten\"\"Jean\" \"Admin\"\"Ainn\" \"Un\" \"suban\"\"Buscopan\"\"hudson\"\"nenein\"\"canarin\" \"Rainan\"  \"Muhsin\"\"American\"\"garsan\"\"Ain\"\"hayinnnnnnnnn\"   \"reclaman\"  \"buscopan\"\"inviten\" \"estaban\" \"liberteen\" \"naman\"\"dan\"  \"fofin\"\"Leon\" \"iguin\"\"Butantan\"\"minion\"\"Jelipin\" \"Quiten\"\"Huan\" \"mimarisin\" \"pedrowestphalen\" \"AnneGonn\"\"heineken\"  \"Westphalen\"\"duran\"\"detran\"\"preparen\"\"rakin\"\"Wilson\"  \"neguin\"\"den\"\"Association\"\"graban\"\"valgan\"\"gustan\"  \"Sen\"\"merlin\"\"haechan\" \"pusieron\"\"Ken\"\"infringen\" \"siguen\"\"gadominion\"\"mmn\"\"sobran\"\"TeichNelson\"\"Lockdown\"  \"Nelson\"\"Watson\"\"Justin\"\"nelson\"\"tahan\"\"Amazon\"  \"hechan\"\"Ewan\" \"Jordan\"\"Allan\"\"lockdown\"\"Johnson\" \"sacaron\" \"can\"\"Morgan\"\"richarlisson\"    \"verifiquen\"\"Verifiquen\" \"Bjin\" \"dersen\"\"empezaron\" \"Brown\"\"Eran\" \"Cedan\" \"Suban\"\"Edilson\" \"manden\"\"faltan\"\"Ubiratan\"\"sorrisin\"  \"Wanderson\" \"Fran\" \"assumption\"\"maaaaan\" \"zen\"\"einstein\"  \"Mandan\"\"tiren\"\"En\" \"difundan\"\"respetan\"\"muestren\"  \"Patterson\" \"Jarun\"\"salgan\"\"Estaban\" \"LockDown\"\"aminin\"  \"chingdizon\"\"compartan\" \"Pongan\"\"borren\"\"acabaron\"\"Iguin\" \"cierren\" \"significan\"\"TlalpanConscien\" \"falten\"\"encantan\"\"olvidaron\" \"tomasfeuermann\"  \"Hoffman\" \"salen\"\"usan\" \"Lan\""
s <- gsub(x=s, pattern = "\\[[0-9]*\\]", replacement = "")
s <- gsub(x=s, pattern = "\\\"", replacement = ",")
s <- gsub(x=s, pattern = " ", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
gsub(x=s, pattern = ",", replacement = '","')
gsub(x=s, pattern = ",", replacement = ',')
tweets[twdf$tweet %like% aux]
library(tm)
library(wordcloud)
library(syuzhet)
library(stringr)
library(stringi)
library(readr)
library(dplyr)
library(data.table)
length(tweets[twdf$tweet %like% aux])
library(tm)
library(wordcloud)
library(syuzhet)
library(stringr)
library(stringi)
library(readr)
library(dplyr)
str_extract(string = tweets$tweet, pattern = "[A-Za-z]*n")
grep(x = tweets$tweet, pattern = "[A-Za-z]*n")
length(tweets[tweets$tweet %like% con])
tweets[tweets$tweet %like% "con"]
tweets[tweets$tweet %like% "con"]
tweets$tweet %like% "con"
length(tweets[tweets$tweet %like% " con ", 1]+
length(tweets[tweets$tweet %like% " con ", 1])
length(tweets[tweets$tweet %like% " con ", 1])
tweets$tweet %like% " con "
tweets$tweet %like% " "
tweets$tweet %like% " con"
tweets$tweet %like% " con\0"
tweets$tweet %like% " con\0"
aux <- gsub(x = unique(aux), pattern =  "[A-Za-z]*n", replacement =  "")
```{r}
tweets <- read.csv("tweetsdb.csv", encoding = "UTF-8")
tweets <- read.csv("tweetsdb.csv", encoding = "UTF-8")
tweets <- tweets[tweets$retweet == "False",]
tweets$date <- str_extract(tweets$date, "[0-9]{4}-[0-9]{2}")
tweets$textf <- textclean1(tweets$tweet)
###Remover Tweets em espanhol
Criei uma heusrística para encontrar tweets em espanhol que vieram classificados como português pelo Twitter.
Palavras
```{r}
aux <- str_extract(string = tweets$tweet, pattern = "[A-Za-z]*n")
aux <- aux[!is.na(aux)]
aux <- gsub(x = unique(aux), pattern =  " ", replacement =  "")
tweets$tweet %like% "[A-Za-z]*n"
str_extract(string = tweets$tweet, pattern = " +[A-Za-z]*n +")
tweets <- read.csv("tweetsdb.csv", encoding = "UTF-8")
tweets$date <- str_extract(tweets$date, "[0-9]{4}-[0-9]{2}")
tweets$textf <- textclean1(tweets$tweet)
aux <- str_extract(string = tweets$tweet, pattern = " +[A-Za-z]*n +")
str_extract(string = tweets$tweet, pattern = " *[A-Za-z]*n *")
str_extract(string = tweets$tweet, pattern = "[A-Za-z]*n ")
length(tweets[tweets$tweet %like% "[A-Za-z]*n ",]$id)
length(tweets[tweets$tweet %like% aux,]$id)
length(tweets[tweets$tweet %like%
"con|Protejan|Bon|compren|Denatran|Tan|enviaron|lan|eran|n|en|mueren|sejan|Ainnn|hajapacien|Bauman|veillon|Irun|implanon|John|min|Jeanzin|quieren|dersin|Man|rebelan|cn|man|fan|han|repiten|sen|Wn|midan|Nn|Minion|Axon|contaron|Brunin|ErickBrianColon|Brian|penn|Florian|nn|dedin|son|Con|presuman|yan|Ninguen|un|bolsominion|cawen|Dan|escribieron|Saben|Hamon|Pokemon|pasan|dangerdirection|dicen|an|van|vmin|finn|jn|roacutan|vitin|Aerolin|borraron|Aeron|Waldman|IrvingChillon|version|Motivacion|seran|ntgen|Ederson|hein|weon|Jacson|veron|deforman|tan|Luan|revelan|MongeHan|Einstein|Van|in|legraton|jeongin|bolsomion|shaman|bailan|Tofen|ainsten|AlbertEinstein|Klan|sobren|Bjorn|jonathan|fin|discuten|Jean|Admin|Ainn|Un|suban|Buscopan|hudson|nenein|canarin|Rainan|Muhsin|American|garsan|Ain|hayinnnnnnnnn|reclaman|buscopan|inviten|estaban|liberteen|naman|dan|fofin|Leon|iguin|Butantan|minion|Jelipin|Quiten|Huan|mimarisin|pedrowestphalen|AnneGonn|heineken|Westphalen|duran|detran|preparen|rakin|Wilson|neguin|den|Association|graban|valgan|gustan|Sen|merlin|haechan|pusieron|Ken|infringen|siguen|gadominion|mmn|sobran|TeichNelson|Lockdown|Nelson|Watson|Justin|nelson|tahan|Amazon|hechan|Ewan|Jordan|Allan|lockdown|Johnson|sacaron|can|Morgan|richarlisson|verifiquen|Verifiquen|Bjin|dersen|empezaron|Brown|Eran|Cedan|Suban|Edilson|manden|faltan|Ubiratan|sorrisin|Wanderson|Fran|assumption|maaaaan|zen|einstein|Mandan|tiren|En|difundan|respetan|muestren|Patterson|Jarun|salgan|Estaban|LockDown|aminin|chingdizon|compartan|Pongan|borren|acabaron|Iguin|cierren|significan|TlalpanConscien|falten|encantan|olvidaron|tomasfeuermann|Hoffman|salen|usan|Lan|"
,]$id)
length(tweets[tweets$tweet %like%
"con|Protejan|Bon|compren|Denatran|Tan|enviaron|lan|eran|n|en|mueren|sejan|Ainnn|hajapacien|Bauman|veillon|Irun|implanon|John|min|Jeanzin|quieren|dersin|Man|rebelan|cn|man|fan|han|repiten|sen|Wn|midan|Nn|Minion|Axon|contaron|Brunin|ErickBrianColon|Brian|penn|Florian|nn|dedin|son|Con|presuman|yan|Ninguen|un|bolsominion|cawen|Dan|escribieron|Saben|Hamon|Pokemon|pasan|dangerdirection|dicen|an|van|vmin|finn|jn|roacutan|vitin|Aerolin|borraron|Aeron|Waldman|IrvingChillon|version|Motivacion|seran|ntgen|Ederson|hein|weon|Jacson|veron|deforman|tan|Luan|revelan|MongeHan|Einstein|Van|in|legraton|jeongin|bolsomion|shaman|bailan|Tofen|ainsten|AlbertEinstein|Klan|sobren|Bjorn|jonathan|fin|discuten|Jean|Admin|Ainn|Un|suban|Buscopan|hudson|nenein|canarin|Rainan|Muhsin|American|garsan|Ain|hayinnnnnnnnn|reclaman|buscopan|inviten|estaban|liberteen|naman|dan|fofin|Leon|iguin|Butantan|minion|Jelipin|Quiten|Huan|mimarisin|pedrowestphalen|AnneGonn|heineken|Westphalen|duran|detran|preparen|rakin|Wilson|neguin|den|Association|graban|valgan|gustan|Sen|merlin|haechan|pusieron|Ken|infringen|siguen|gadominion|mmn|sobran|TeichNelson|Lockdown|Nelson|Watson|Justin|nelson|tahan|Amazon|hechan|Ewan|Jordan|Allan|lockdown|Johnson|sacaron|can|Morgan|richarlisson|verifiquen|Verifiquen|Bjin|dersen|empezaron|Brown|Eran|Cedan|Suban|Edilson|manden|faltan|Ubiratan|sorrisin|Wanderson|Fran|assumption|maaaaan|zen|einstein|Mandan|tiren|En|difundan|respetan|muestren|Patterson|Jarun|salgan|Estaban|LockDown|aminin|chingdizon|compartan|Pongan|borren|acabaron|Iguin|cierren|significan|TlalpanConscien|falten|encantan|olvidaron|tomasfeuermann|Hoffman|salen|usan|Lan"
,]$id)
length(tweets[tweets$tweet %like%
"(con)|(Protejan)|(Bon)|(compren)|(Denatran)|(Tan)|(enviaron)|(lan)|(eran)|(n)|(en)|(mueren)|(sejan)|(Ainnn)|(hajapacien)|(Bauman)|(veillon)|(Irun)|(implanon)|(John)|(min)|(Jeanzin)|(quieren)|(dersin)|(Man)|(rebelan)|(cn)|(man)|(fan)|(han)|(repiten)|(sen)|(Wn)|(midan)|(Nn)|(Minion)|(Axon)|(contaron)|(Brunin)|(ErickBrianColon)|(Brian)|(penn)|(Florian)|(nn)|(dedin)|(son)|(Con)|(presuman)|(yan)|(Ninguen)|(un)|(bolsominion)|(cawen)|(Dan)|(escribieron)|(Saben)|(Hamon)|(Pokemon)|(pasan)|(dangerdirection)|(dicen)|(an)|(van)|(vmin)|(finn)|(jn)|(roacutan)|(vitin)|(Aerolin)|(borraron)|(Aeron)|(Waldman)|(IrvingChillon)|(version)|(Motivacion)|(seran)|(ntgen)|(Ederson)|(hein)|(weon)|(Jacson)|(veron)|(deforman)|(tan)|(Luan)|(revelan)|(MongeHan)|(Einstein)|(Van)|(in)|(legraton)|(jeongin)|(bolsomion)|(shaman)|(bailan)|(Tofen)|(ainsten)|(AlbertEinstein)|(Klan)|(sobren)|(Bjorn)|(jonathan)|(fin)|(discuten)|(Jean)|(Admin)|(Ainn)|(Un)|(suban)|(Buscopan)|(hudson)|(nenein)|(canarin)|(Rainan)|(Muhsin)|(American)|(garsan)|(Ain)|(hayinnnnnnnnn)|(reclaman)|(buscopan)|(inviten)|(estaban)|(liberteen)|(naman)|(dan)|(fofin)|(Leon)|(iguin)|(Butantan)|(minion)|(Jelipin)|(Quiten)|(Huan)|(mimarisin)|(pedrowestphalen)|(AnneGonn)|(heineken)|(Westphalen)|(duran)|(detran)|(preparen)|(rakin)|(Wilson)|(neguin)|(den)|(Association)|(graban)|(valgan)|(gustan)|(Sen)|(merlin)|(haechan)|(pusieron)|(Ken)|(infringen)|(siguen)|(gadominion)|(mmn)|(sobran)|(TeichNelson)|(Lockdown)|(Nelson)|(Watson)|(Justin)|(nelson)|(tahan)|(Amazon)|(hechan)|(Ewan)|(Jordan)|(Allan)|(lockdown)|(Johnson)|(sacaron)|(can)|(Morgan)|(richarlisson)|(verifiquen)|(Verifiquen)|(Bjin)|(dersen)|(empezaron)|(Brown)|(Eran)|(Cedan)|(Suban)|(Edilson)|(manden)|(faltan)|(Ubiratan)|(sorrisin)|(Wanderson)|(Fran)|(assumption)|(maaaaan)|(zen)|(einstein)|(Mandan)|(tiren)|(En)|(difundan)|(respetan)|(muestren)|(Patterson)|(Jarun)|(salgan)|(Estaban)|(LockDown)|(aminin)|(chingdizon)|(compartan)|(Pongan)|(borren)|(acabaron)|(Iguin)|(cierren)|(significan)|(TlalpanConscien)|(falten)|(encantan)|(olvidaron)|(tomasfeuermann)|(Hoffman)|(salen)|(usan)|(Lan)"
,]$id)

---
title: "Análise de Sentimentos SUS"
author: "Henrique Silva"
date: "10/10/2020"
output: html_document
---
##Libraries
```{r setup} 
library(tm)
library(wordcloud)
library(syuzhet)
library(stringr)
library(stringi)
library(readr)
library(dplyr)
```

```{r, include=FALSE}
setwd("~/GitHub/SUS-Sentiment-Analysis/Projeto")
```


##Constantes

```{r}
sent_labels <- c("Raiva", "Antecipação", "Nojo", "Medo", "Alegria", 
"Tristeza", "Surpesa", "Confiança", "Negativo", "Positivo", "Neutral")

months <- c("Dez 2019", "Jan 2020", "Fev 2020", "Mar 2020", "Abril 2020", 
"Maio 2020")
```

## Functions
```{r}
textclean1 <- function(text_list){
  aux <- text_list
  removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
  aux <-  readr::parse_character(aux, locale = readr::locale('pt'))
  aux <- sapply(aux, function(x) stri_trans_tolower(x,'pt')) # Por tudo em letras minúsculas
  aux <- gsub("<[Uu]\\+[a-zA-Z0-9]*>", "",  aux); # Remover Emojis
  aux <- gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "",  aux);
  aux <- str_replace(aux,"RT @[a-z,A-Z]*: ","")
  aux <- gsub("@\\w+", "", aux)
  aux <- removeURL(aux)
  aux <- str_replace_all(aux,"@[a-zA-Z]*","") # Remover marcações @username
  aux <- gsub("[^[:alnum:][:blank:]!?]", "", aux)
  aux <- gsub("[[:digit:]]", "", aux)
  return(aux)
}

build_corpus <- function(text_listf, rwords=NULL){
  tweets_t <- paste(text_listf,collapse=" ")
  tweets_S <- VectorSource(tweets_t)
  corpus <- Corpus(tweets_S)
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, stripWhitespace)
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, removeWords, stopwords("portuguese"))
  corpus <- tm_map(corpus, removeWords, rwords)
  return(corpus)
}

get_sentiment <- function(text_listf, title="Sentimentos"){
  s <- get_nrc_sentiment(text_listf, language = "portuguese")
  s$neutral <- (s$positive == s$negative)>0
  s$positive <- (s$positive > s$negative)>0
  s$negative <- (s$positive == 0 & s$neutral == 0)>0
  colnames(s) <- sent_labels
  barplot(colSums(s),las=2,col=rainbow(10), ylab= "Quantidade", 
main=title)
  return(s)
}

get_freq <- function(text_listf, rwords=NULL, cloud_max_words = 100){
  corpus <- build_corpus(text_listf, rwords)
  dtm <-TermDocumentMatrix(corpus)
  dtm <- as.matrix(dtm)
  fre <- sort(rowSums(dtm),decreasing=TRUE)
  wordcloud(names(fre),freq=fre,min.freq=1,max.words=cloud_max_words,scale=c(4,.5),
 random.order=F, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
  return(fre)
}
```

##Carregar dados e limpar dados

```{r}
tweets <- read.csv("tweetsdb.csv", encoding = "UTF-8")

tweets <- tweets[tweets$retweet == "False",]

tweets$date <- str_extract(tweets$date, "[0-9]{4}-[0-9]{2}")

tweets$textf <- textclean1(tweets$tweet)
```

###Remover Tweets em espanhol
Criei uma heusrística para encontrar tweets em espanhol que vieram classificados como português pelo Twitter.
Palavras 

```{r}
aux <- str_extract(string = tweets$tweet, pattern = "[A-Za-z]*n ")
aux <- aux[!is.na(aux)]
aux <- gsub(x = unique(aux), pattern =  " ", replacement =  "")

length(tweets[tweets$tweet %like%"     "]$id)

c("con","Protejan","Bon","compren","Tan","enviaron","lan","eran","n","en","mueren","sejan","hajapacien","veillon","implanon","quieren","rebelan","repiten","contaron","Brunin","son","Con","presuman","yan","Ninguen","un","escribieron","Saben","Hamon","Pokemon","pasan","dangerdirection","dicen","an","van","vmin","finn","jn","roacutan","vitin","Aerolin","borraron","Motivacion","seran","deforman","tan","Luan","revelan","MongeHan","Einstein","Van","in","legraton","jeongin","bolsomion","shaman","bailan","Tofen","ainsten","AlbertEinstein","Klan","sobren","Bjorn","jonathan","fin","discuten","Jean","Admin","Ainn","Un","suban","Buscopan","hudson","nenein","canarin","Rainan","Muhsin","American","garsan","Ain","hayinnnnnnnnn","reclaman","buscopan","inviten","estaban","liberteen","naman","dan","fofin","Leon","iguin","Butantan","minion","Jelipin","Quiten","Huan","mimarisin","pedrowestphalen","AnneGonn","heineken","Westphalen","duran","detran","preparen","rakin","Wilson","neguin","den","Association","graban","valgan","gustan","Sen","merlin","haechan","pusieron","Ken","infringen","siguen","gadominion","mmn","sobran","TeichNelson","Lockdown","Nelson","Watson","Justin","nelson","tahan","Amazon","hechan","Ewan","Jordan","Allan","lockdown","Johnson","sacaron","can","Morgan","richarlisson","verifiquen","Verifiquen","Bjin","dersen","empezaron","Brown","Eran","Cedan","Suban","Edilson","manden","faltan","Ubiratan","sorrisin","Wanderson","Fran","assumption","maaaaan","zen","einstein","Mandan","tiren","En","difundan","respetan","muestren","Patterson","Jarun","salgan","Estaban","LockDown","aminin","chingdizon","compartan","Pongan","borren","acabaron","Iguin","cierren","significan","TlalpanConscien","falten","encantan","olvidaron","tomasfeuermann","Hoffman","salen","usan","Lan")

s <- gsub(x=s, pattern = "\\[[0-9]*\\]", replacement = "")
s <- gsub(x=s, pattern = "\\\"", replacement = ",")
s <- gsub(x=s, pattern = " ", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",,", replacement = ",")
s <- gsub(x=s, pattern = ",", replacement = ',')

head((tweets %>% select(id, date, tweet, textf)), n = 10)
```


```{r, cache=TRUE, warning=FALSE, message=FALSE }

tp1 <- tweets[tweets$date == "2019-12",]
tp2 <- tweets[tweets$date == "2020-01",]
tp3 <- tweets[tweets$date == "2020-02",]
tp4 <- tweets[tweets$date == "2020-03",]
tp5 <- tweets[tweets$date == "2020-04",]
tp6 <- tweets[tweets$date == "2020-05",]

ncloud = 200
words<- c("sus", "pra", "pro", "né", "tá", "vcs", "tô", "aí")
tp1.fre <- get_freq(tp1$textf,  rwords=words, cloud_max_words = ncloud)
tp1.s <- get_sentiment(tp1$textf, "Sentimentos Dez 2019")

tp2.fre <- get_freq(tp2$textf,  rwords=words, cloud_max_words = ncloud)
tp2.s <- get_sentiment(tp2$textf, "Sentimentos Jan 2020")

tp3.fre <- get_freq(tp3$textf,  rwords=words, cloud_max_words = ncloud)
tp3.s <- get_sentiment(tp3$textf, "Sentimentos Fev 2020")

tp4.fre <- get_freq(tp4$textf,  rwords=words, cloud_max_words = ncloud)
tp4.s <- get_sentiment(tp4$textf, "Sentimentos Mar 2020")

tp5.fre <- get_freq(tp5$textf,  rwords=words, cloud_max_words = ncloud)
tp5.s <- get_sentiment(tp5$textf, "Sentimentos Abril 2020")

tp6.fre <- get_freq(tp6$textf,  rwords=words, cloud_max_words = ncloud)
tp6.s <- get_sentiment(tp6$textf, "Sentimentos Maio 2020")

```

```{r}
#df <- matrix(c(colSums(tp1.s),colSums(tp2.s),colSums(tp3.s),colSums(tp4.s),colSums(tp5.s),colSums(tp6.s)), nrow = 6, ncol = 10, byrow = T)
#barplot(df, col=rainbow(length(pos_neg[1,])), names.arg = sent_labels, beside = T, las=2)
#legend("topleft", pch = 15, col = rainbow(length(pos_neg[1,])), months)


df <- matrix(c(colSums(tp1.s>0),colSums(tp2.s>0),colSums(tp3.s>0),colSums(tp4.s>0),colSums(tp5.s>0),colSums(tp6.s>0)), nrow = 11, ncol = 6, byrow = F)

barplot(df, col=rainbow(length(df[,1])), names.arg = months, beside = T)
legend("topleft", pch = 15, col = rainbow(length(df[,1])), sent_labels, cex = 0.75)


```
### Comparativo
```{r}
col_posneg <- c(9:11)
pos_neg <- df[col_posneg,]
aux <- pos_neg
for (i in c(1:length(pos_neg[1,]))) {
  for (j in c(1:length(pos_neg[,1]))) {
    pos_neg[j,i] <- (pos_neg[j,i]/ sum(aux[,i]))*100
  }
}
col_sents <- c(1, 3, 4, 5, 6, 8)
sent <- df[c(col_sents),]

barplot(pos_neg, col=rainbow(length(pos_neg[,1])), names.arg = months, beside = T, xlab = "Mês", ylab="Percentual(%)", main= "Sentimentos positivos e negativos no período de pesquisa")
legend("topright", pch = 15, col = rainbow(length(pos_neg[,1])), sent_labels[col_posneg], cex = 0.75)
```

```{r}
col_sents <- c(1, 3, 4, 5, 6, 8)
sent <- df[c(col_sents),]

barplot(sent, col=rainbow(length(sent[,1])), names.arg = months, beside = T, xlab = "Mês", ylab="Frequencia em Tweets", main= "Sentimentos encontrados por quantidade no período de pesquisa")
legend("topleft", pch = 15, col = rainbow(length(sent[,1])), sent_labels[col_sents], cex = 0.75)
```




